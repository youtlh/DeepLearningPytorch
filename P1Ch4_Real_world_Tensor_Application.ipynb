{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNwUsu7hHHHE/R48xB5Wb1u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youtlh/DeepLearningPytorch/blob/main/P1Ch4_Real_world_Tensor_Application.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Images"
      ],
      "metadata": {
        "id": "PiqnmqWjVLpV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpHoBqbCh2OO",
        "outputId": "d2598f9e-93ca-4c64-b06f-b6be1dd64ce7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(720, 1280, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "import imageio\n",
        "url = 'https://raw.githubusercontent.com/deep-learning-with-pytorch/dlwpt-code/master/data/p1ch4/image-dog/bobby.jpg'\n",
        "page = requests.get(url)\n",
        "img_arr = imageio.imread(BytesIO(page.content))\n",
        "img_arr.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "img = torch.from_numpy(img_arr)\n",
        "out = img.permute(2, 0, 1) # torch deals with layout channel * height * width, change the layout by having channel 2 first and then channels 0 and 1.\n",
        "# This operation does not make a copy of the tensor data. out uses the same underlying storage as img and only plays with the size and stride information.\n",
        "# Note, that changing a pixel in img will leads to a change in out.\n",
        "# Read multiple images using this method and store the images in a batch along the first dimension to obtain an N * C * H * W tensor."
      ],
      "metadata": {
        "id": "Q2ddmpfGVpK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A more efficient way to do this is to build the tensor first and then fill in with images\n",
        "batch_size = 3\n",
        "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)\n",
        "\n",
        "import os\n",
        "data_dir = '...' # directory for images\n",
        "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.png']\n",
        "for i, filename in enumerate(filenames):\n",
        "  img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
        "  img_t = torch.from_numpy(img_arr)\n",
        "  img_t = img_t.permute(2, 0, 1)\n",
        "  img_t = img_t[:3]\n",
        "  # insert preprocess transform step to resize picture\n",
        "  batch[i] = img_t"
      ],
      "metadata": {
        "id": "e1vpQdWzWAuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change the data to float type\n",
        "batch = batch.float()\n",
        "# normalize it to 0-1 or -1-1\n",
        "batch /= 255.0\n",
        "# or\n",
        "n_channels = batch.shape[1]\n",
        "for c in range(n_channels):\n",
        "  mean = torch.mean(batch[:, c])\n",
        "  std = torch.std(batch[:, c])\n",
        "  batch[:, c] = (batch[:, c]-mean)/std"
      ],
      "metadata": {
        "id": "S5tweP5Jd8wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read multiple files (CT scan files -> include depth dimension)\n",
        "dir_path = \"...\"\n",
        "vol_arr = imageio.volread(dir_path, 'DICOM')\n",
        "vol_arr.shape\n",
        "# return (99, 512, 512) -> (depth, height, width). For 5D tensor, the shape should be N*C*D*H*W."
      ],
      "metadata": {
        "id": "Fuu3Ppn8gCnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add channel dimension using unsqueeze\n",
        "vol = torch.from_numpy(vol_arr).float()\n",
        "vol = torch.unsqueeze(vol, 0)\n",
        "vol.shape\n",
        "# return (1, 99, 512, 512)"
      ],
      "metadata": {
        "id": "R72oKPNIgEdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tabular"
      ],
      "metadata": {
        "id": "0ed8mPA0h8qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "wine_numpy = pd.read_csv(\"https://raw.githubusercontent.com/deep-learning-with-pytorch/dlwpt-code/master/data/p1ch4/tabular-wine/winequality-white.csv\", delimiter=';', dtype=np.float32)\n",
        "wine_numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Ww_3FHPhh-iE",
        "outputId": "888b967e-ce1d-477e-b451-c376f6121de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0               7.0              0.27         0.36       20.700001      0.045   \n",
              "1               6.3              0.30         0.34        1.600000      0.049   \n",
              "2               8.1              0.28         0.40        6.900000      0.050   \n",
              "3               7.2              0.23         0.32        8.500000      0.058   \n",
              "4               7.2              0.23         0.32        8.500000      0.058   \n",
              "...             ...               ...          ...             ...        ...   \n",
              "4893            6.2              0.21         0.29        1.600000      0.039   \n",
              "4894            6.6              0.32         0.36        8.000000      0.047   \n",
              "4895            6.5              0.24         0.19        1.200000      0.041   \n",
              "4896            5.5              0.29         0.30        1.100000      0.022   \n",
              "4897            6.0              0.21         0.38        0.800000      0.020   \n",
              "\n",
              "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
              "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
              "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
              "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
              "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
              "...                   ...                   ...      ...   ...        ...   \n",
              "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
              "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
              "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
              "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
              "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
              "\n",
              "      alcohol  quality  \n",
              "0         8.8      6.0  \n",
              "1         9.5      6.0  \n",
              "2        10.1      6.0  \n",
              "3         9.9      6.0  \n",
              "4         9.9      6.0  \n",
              "...       ...      ...  \n",
              "4893     11.2      6.0  \n",
              "4894      9.6      5.0  \n",
              "4895      9.4      6.0  \n",
              "4896     12.8      7.0  \n",
              "4897     11.8      6.0  \n",
              "\n",
              "[4898 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-322189ca-650b-4bee-a6ec-c60e0e43e9be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.36</td>\n",
              "      <td>20.700001</td>\n",
              "      <td>0.045</td>\n",
              "      <td>45.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1.00100</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>8.8</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.049</td>\n",
              "      <td>14.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.99400</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.49</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.40</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>0.050</td>\n",
              "      <td>30.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.99510</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.44</td>\n",
              "      <td>10.1</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.99560</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.99560</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4893</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.039</td>\n",
              "      <td>24.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.99114</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4894</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.36</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.047</td>\n",
              "      <td>57.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.6</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4895</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.041</td>\n",
              "      <td>30.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.99254</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.4</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4896</th>\n",
              "      <td>5.5</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>0.022</td>\n",
              "      <td>20.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.98869</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.38</td>\n",
              "      <td>12.8</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4897</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.020</td>\n",
              "      <td>22.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.98941</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.32</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4898 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-322189ca-650b-4bee-a6ec-c60e0e43e9be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-322189ca-650b-4bee-a6ec-c60e0e43e9be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-322189ca-650b-4bee-a6ec-c60e0e43e9be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the numpy array to torch tensor\n",
        "wineq = torch.from_numpy(wine_numpy.values)\n",
        "wineq.shape, wineq.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAfqFeoajnT3",
        "outputId": "58797816-681a-4966-9743-9725876c2773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898, 12]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# exclude the last target column\n",
        "data = wineq[:, :-1]\n",
        "data, data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGl8sOr7xwk7",
        "outputId": "9a7c6a7d-d4f2-4d39-96b3-8c068fc05e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
              "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
              "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
              "         ...,\n",
              "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
              "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
              "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
              " torch.Size([4898, 11]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = wineq[:, -1].long()\n",
        "target, target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6wLbBS20LDV",
        "outputId": "b62ddd6a-99f3-47c7-d835-ed9ed8ea0b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([6, 6, 6,  ..., 6, 7, 6]), torch.Size([4898]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encoding for categorical column. For pytorch, is wnat to use categorical input to network, need to transfrom it to one-hot-encoded tensor\n",
        "target_onehot = torch.zeros(target.shape[0], 10)\n",
        "target_onehot.scatter_(1, target.unsqueeze(1), 1.0) # _ after function name meaning that this method will not return a new tensor\n",
        "# scatter_ takes the following arguments: 1. dimension along which the following two arguments 2. column tensor indicating the indices of the elements to scatter 3. the element to scatter, 1 for one-hot encoding\n",
        "# target.unsqueeze(1) returns tensor with shape [4898, 1], the one-hot encoding is expended on the [1] dimension."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7xLA1hU0SRr",
        "outputId": "1b7d985a-88e2-4b2e-bfda-af3bfb71480e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize data\n",
        "data_mean = torch.mean(data, dim=0) # the dim=0 means that the reduction is performed along dimension 0\n",
        "data_var = torch.var(data, dim=0)\n",
        "data_normalized = (data - data_mean) / torch.sqrt(data_var)"
      ],
      "metadata": {
        "id": "T8t2i_So1yd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_data = data[target <= 3]\n",
        "mid_data = data[(target > 3) & (target < 7)]\n",
        "good_data = data[target >= 7]\n",
        "bad_mean = torch.mean(bad_data, dim=0)\n",
        "mid_mean = torch.mean(mid_data, dim=0)\n",
        "good_mean = torch.mean(good_data, dim=0)\n",
        "for i, args in enumerate(zip(wine_numpy.columns.tolist(), bad_mean, mid_mean, good_mean)):\n",
        "  print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISWa4vhy6MsN",
        "outputId": "bf0bc3aa-0478-438b-8c7b-3951fe41cfb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0 fixed acidity          7.60   6.89   6.73\n",
            " 1 volatile acidity       0.33   0.28   0.27\n",
            " 2 citric acid            0.34   0.34   0.33\n",
            " 3 residual sugar         6.39   6.71   5.26\n",
            " 4 chlorides              0.05   0.05   0.04\n",
            " 5 free sulfur dioxide   53.33  35.42  34.55\n",
            " 6 total sulfur dioxide 170.60 141.83 125.25\n",
            " 7 density                0.99   0.99   0.99\n",
            " 8 pH                     3.19   3.18   3.22\n",
            " 9 sulphates              0.47   0.49   0.50\n",
            "10 alcohol               10.34  10.26  11.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Series"
      ],
      "metadata": {
        "id": "_lkLlE4V8jyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bikes_df = pd.read_csv(\"https://raw.githubusercontent.com/deep-learning-with-pytorch/dlwpt-code/master/data/p1ch4/bike-sharing-dataset/hour-fixed.csv\")\n",
        "bikes_df['dteday'] = bikes_df.dteday.apply(lambda dte: int(dte[8:10]))\n",
        "bikes_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Q5zZJCmq7AHj",
        "outputId": "c8b9c0bb-871c-4703-a23d-7ba11b5d5d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       instant  dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
              "0            1       1       1   0     1   0        0        6           0   \n",
              "1            2       1       1   0     1   1        0        6           0   \n",
              "2            3       1       1   0     1   2        0        6           0   \n",
              "3            4       1       1   0     1   3        0        6           0   \n",
              "4            5       1       1   0     1   4        0        6           0   \n",
              "...        ...     ...     ...  ..   ...  ..      ...      ...         ...   \n",
              "17515    17375      31       1   1    12  19        0        1           1   \n",
              "17516    17376      31       1   1    12  20        0        1           1   \n",
              "17517    17377      31       1   1    12  21        0        1           1   \n",
              "17518    17378      31       1   1    12  22        0        1           1   \n",
              "17519    17379      31       1   1    12  23        0        1           1   \n",
              "\n",
              "       weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
              "0               1  0.24  0.2879  0.81     0.0000       3          13   16  \n",
              "1               1  0.22  0.2727  0.80     0.0000       8          32   40  \n",
              "2               1  0.22  0.2727  0.80     0.0000       5          27   32  \n",
              "3               1  0.24  0.2879  0.75     0.0000       3          10   13  \n",
              "4               1  0.24  0.2879  0.75     0.0000       0           1    1  \n",
              "...           ...   ...     ...   ...        ...     ...         ...  ...  \n",
              "17515           2  0.26  0.2576  0.60     0.1642      11         108  119  \n",
              "17516           2  0.26  0.2576  0.60     0.1642       8          81   89  \n",
              "17517           1  0.26  0.2576  0.60     0.1642       7          83   90  \n",
              "17518           1  0.26  0.2727  0.56     0.1343      13          48   61  \n",
              "17519           1  0.26  0.2727  0.65     0.1343      12          37   49  \n",
              "\n",
              "[17520 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91aab8a2-8ca9-4e61-aaf8-9d7ebac7fa8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17515</th>\n",
              "      <td>17375</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.1642</td>\n",
              "      <td>11</td>\n",
              "      <td>108</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17516</th>\n",
              "      <td>17376</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.1642</td>\n",
              "      <td>8</td>\n",
              "      <td>81</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17517</th>\n",
              "      <td>17377</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.1642</td>\n",
              "      <td>7</td>\n",
              "      <td>83</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17518</th>\n",
              "      <td>17378</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>13</td>\n",
              "      <td>48</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17519</th>\n",
              "      <td>17379</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>12</td>\n",
              "      <td>37</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17520 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91aab8a2-8ca9-4e61-aaf8-9d7ebac7fa8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91aab8a2-8ca9-4e61-aaf8-9d7ebac7fa8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91aab8a2-8ca9-4e61-aaf8-9d7ebac7fa8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The standard time series tensor format is dimension 3 and shape N * C * L. N is the number of samples inside each observation periods. C number of columns inside the 2D dataframe. L is the number of groups introducced by dividing observation periods (2 year data break up into days). Need to take care of data if there's any gaps in the time series."
      ],
      "metadata": {
        "id": "MK2GOu8n-p-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bikes = torch.from_numpy(bikes_df.values)\n",
        "bikes = bikes.contiguous()"
      ],
      "metadata": {
        "id": "ojjQxcvL9ad9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bikes.shape, bikes.stride()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJm-4iDWBaKT",
        "outputId": "c6765a37-bd34-4981-c80a-d5f4a2a1ffaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([17520, 17]), (17, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "daily_bikes = bikes.view(-1, 24, bikes.shape[1])\n",
        "daily_bikes.shape, daily_bikes.stride()\n",
        "# .view() returns a new tensor that changes the number of dimensions and the striding information, without changing the storage."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs1rzPHSBfTT",
        "outputId": "7773eafe-e465-43ef-de50-2a69a6d58325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([730, 24, 17]), (408, 17, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chnge the format to NCL\n",
        "daily_bikes = daily_bikes.transpose(1, 2)\n",
        "daily_bikes.shape, daily_bikes.stride()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_TzOJW0B3tS",
        "outputId": "47f4940a-8ffc-4533-ae66-be65497028fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([730, 17, 24]), (408, 1, 17))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-hot Encoding"
      ],
      "metadata": {
        "id": "bwxtIE3bZCMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first limit to first day just to check the logic\n",
        "first_day = bikes[:24].long()\n",
        "weather_onehot = torch.zeros(first_day.shape[0], 4)\n",
        "first_day[:,9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSSRFlZ4DCwM",
        "outputId": "72fba21d-9514-4685-ec2e-2094592c3c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_day.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nuvu4vWzWS8y",
        "outputId": "1ac3f664-441c-4b62-80ef-e66d823cdf89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([24, 17])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weather_onehot.scatter_(\n",
        "  dim=1,\n",
        "  index=first_day[:,9].unsqueeze(1).long()-1, # need to -1 because the first day value is between 1-4. while for one-hot encoding, the index is 0 based.\n",
        "  value=1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F8qJjPnPCTe",
        "outputId": "8580b675-f877-4f44-cea7-1ae74d7d598e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate the one-hot matrix to the original dataset\n",
        "torch.cat((bikes[:24], weather_onehot), 1)[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-0m1q9VQzdC",
        "outputId": "a3000c95-d6c8-40e0-eedf-2ff3ca65fa8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
              "          0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
              "         16.0000,  0.0000,  0.0000,  0.0000,  0.0000]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finally apply to the target daily_bikes tensor\n",
        "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4, daily_bikes.shape[2]) # note the one-hot encode needs to conform the original tensor dimension\n",
        "daily_weather_onehot.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtuAvLC9Trrz",
        "outputId": "722a6127-e17d-4fa4-b1ac-34b846656217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([730, 4, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "daily_weather_onehot.scatter_(1, daily_bikes[:,9,:].long().unsqueeze(1) - 1, 1.0)\n",
        "daily_weather_onehot.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLLtauC3WBaI",
        "outputId": "8c7121a3-1139-4a0e-a10f-26af2f76f28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([730, 4, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), dim=1) # note to cancatenate on the C direction"
      ],
      "metadata": {
        "id": "3sIOnJwPWoJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apart from encode the weather as categorical variable, one could also treat it as ordinal variable. Then we only need to standardize it."
      ],
      "metadata": {
        "id": "GH40GhbuZKdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# daily_bikes[:, 9, :] = (daily_bikes[:, 9, :] - 1.0) / 3.0"
      ],
      "metadata": {
        "id": "aRnEgTEaYQWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization"
      ],
      "metadata": {
        "id": "3tN9DneUdAQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# map the value to [0,1]\n",
        "temp = daily_bikes[:, 10, :]\n",
        "temp_min = torch.min(temp)\n",
        "temp_max = torch.max(temp)\n",
        "daily_bikes[:, 10, :] = ((daily_bikes[:, 10, :] - temp_min) / (temp_max - temp_min))"
      ],
      "metadata": {
        "id": "4l6wLkwcZl97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standardize\n",
        "temp = daily_bikes[:, 10, :]\n",
        "daily_bikes[:, 10, :] = ((daily_bikes[:, 10, :] - torch.mean(temp)) / torch.std(temp))"
      ],
      "metadata": {
        "id": "hsok3rtQd0_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text"
      ],
      "metadata": {
        "id": "xjOhsB0Sh4TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "master = \"https://raw.githubusercontent.com/deep-learning-with-pytorch/dlwpt-code/master/data/p1ch4/jane-austen/1342-0.txt\"\n",
        "req = requests.get(master)\n",
        "text = req.text"
      ],
      "metadata": {
        "id": "MOlEpPkvh5gQ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = text.split('\\n')\n",
        "line = lines[200]\n",
        "line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AhUNGOY5jXhe",
        "outputId": "7f79386c-3d13-4da1-93db-772b070b8525"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'“Impossible, Mr. Bennet, impossible, when I am not acquainted with him'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-hot Encoding"
      ],
      "metadata": {
        "id": "RhmMb17vkJNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding Characters"
      ],
      "metadata": {
        "id": "oyx0z8gWkjby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "letter_t = torch.zeros(len(line), 128) # using ASCII 128 to represent characters\n",
        "letter_t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0mHjjvqjylN",
        "outputId": "3c183244-ad4c-447c-a663-3d31ca117b87"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([70, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, letter in enumerate(line.lower().strip()):\n",
        "  letter_index = ord(letter) if ord(letter) < 128 else 0\n",
        "  letter_t[i][letter_index] = 1"
      ],
      "metadata": {
        "id": "JLpJFnnOkD0V"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding Words"
      ],
      "metadata": {
        "id": "Of2XCTojkptQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the punctuation symbols and \\n\n",
        "def clean_words(input_str):\n",
        "  punctuation = '.,;:\"!?”“_-'\n",
        "  word_list = input_str.lower().replace('\\n',' ').split()\n",
        "  word_list = [word.strip(punctuation) for word in word_list] \n",
        "  return word_list\n",
        "\n",
        "words_in_line = clean_words(line)\n",
        "line, words_in_line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AWURIImkTdd",
        "outputId": "4f1b0358-2260-47f7-d31c-2a05c79a31e1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('“Impossible, Mr. Bennet, impossible, when I am not acquainted with him',\n",
              " ['impossible',\n",
              "  'mr',\n",
              "  'bennet',\n",
              "  'impossible',\n",
              "  'when',\n",
              "  'i',\n",
              "  'am',\n",
              "  'not',\n",
              "  'acquainted',\n",
              "  'with',\n",
              "  'him'])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build a mapping between all the words in text with index\n",
        "word_list = sorted(set(clean_words(text)))\n",
        "word2index_dict = {word: i for (i, word) in enumerate(word_list)}\n",
        "len(word2index_dict), word2index_dict['impossible']\n",
        "# word2index_dict is a dictionary with words as keys and integer as value."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4QM7fNklpP-",
        "outputId": "adf6aae9-6b1c-41c2-c9f8-8448d0ca8ae9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7261, 3394)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_t = torch.zeros(len(words_in_line), len(word2index_dict))\n",
        "for i, word in enumerate(words_in_line):\n",
        "  word_index = word2index_dict[word]\n",
        "  word_t[i][word_index] = 1\n",
        "  print('{:2} {:4} {}'.format(i, word_index, word))\n",
        "print(word_t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zUOpO_Llx7C",
        "outputId": "d6877c45-561c-4cd2-a4d5-74c517aa03b2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0 3394 impossible\n",
            " 1 4305 mr\n",
            " 2  813 bennet\n",
            " 3 3394 impossible\n",
            " 4 7078 when\n",
            " 5 3315 i\n",
            " 6  415 am\n",
            " 7 4436 not\n",
            " 8  239 acquainted\n",
            " 9 7148 with\n",
            "10 3215 him\n",
            "torch.Size([11, 7261])\n"
          ]
        }
      ]
    }
  ]
}