{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOo36BXMMU3OUD36RbVfImb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youtlh/DeepLearningPytorch/blob/main/P1Ch5_6_Learning_mechanics_and_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Mechanics"
      ],
      "metadata": {
        "id": "AcmGuDrSkAAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0] # ground truth\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4] # observations\n",
        "t_c = torch.tensor(t_c)\n",
        "t_u = torch.tensor(t_u)"
      ],
      "metadata": {
        "id": "E_LOKio7jm9Q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build a simple linear model with two parameters to fit, w and b\n",
        "def model(t_u, w, b):\n",
        "  return w * t_u + b"
      ],
      "metadata": {
        "id": "sE1U5WT3j3he"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the tensor for parameters\n",
        "w = torch.ones(())\n",
        "b = torch.zeros(())\n",
        "t_p = model(t_u, w, b)\n",
        "t_p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGErOFirjxl6",
        "outputId": "638d0308-995f-40e7-cf22-10cfd3154565"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
              "        48.4000, 60.4000, 68.4000])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss and Gradient"
      ],
      "metadata": {
        "id": "wD_lmPyokg5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simple mean square error loss function\n",
        "def loss_fn(t_p, t_c):\n",
        "  squared_diffs = (t_p - t_c)**2\n",
        "  return squared_diffs.mean()"
      ],
      "metadata": {
        "id": "VZ8hfi5TkE8Q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the loss\n",
        "loss = loss_fn(t_p, t_c)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCKG6MmlkCno",
        "outputId": "87d187bf-5476-4612-d9f0-29441e2610c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1763.8848)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# estimate the rate of change (local derivative) by adding a small number to w and b and seeing how much the loss changes in that neighborhood\n",
        "# shift the parameter by derivative * learning rate\n",
        "delta = 0.1\n",
        "learning_rate = 1e-2\n",
        "\n",
        "loss_rate_of_change_w = \\\n",
        "  (loss_fn(model(t_u, w + delta, b), t_c) -\n",
        "  loss_fn(model(t_u, w - delta, b), t_c)) / (2.0 * delta)\n",
        "w = w - learning_rate * loss_rate_of_change_w\n",
        "\n",
        "loss_rate_of_change_b = \\\n",
        "  (loss_fn(model(t_u, w, b + delta), t_c) -\n",
        "  loss_fn(model(t_u, w, b - delta), t_c)) / (2.0 * delta)\n",
        "b = b - learning_rate * loss_rate_of_change_b"
      ],
      "metadata": {
        "id": "RvoNn7WukQf0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to compute the derivative analytically dx^2/dx = 2x\n",
        "def dloss_fn(t_p, t_c):\n",
        "  dsq_diffs = 2 * (t_p - t_c) / t_p.size(0) # division comes from the derivative of mean\n",
        "  return dsq_diffs"
      ],
      "metadata": {
        "id": "gt9hGP2Vkjux"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying the derivatives to the model\n",
        "def dmodel_dw(t_u, w, b):\n",
        "  return t_u\n",
        "\n",
        "def dmodel_db(t_u, w, b):\n",
        "  return 1.0"
      ],
      "metadata": {
        "id": "pmCiQ8Xnkwgz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the gradient function\n",
        "def grad_fn(t_u, t_c, t_p, w, b):\n",
        "  dloss_dtp = dloss_fn(t_p, t_c)\n",
        "  dloss_dw = dloss_dtp * dmodel_dw(t_u, w, b)\n",
        "  dloss_db = dloss_dtp * dmodel_db(t_u, w, b)\n",
        "  return torch.stack([dloss_dw.sum(), dloss_db.sum()])"
      ],
      "metadata": {
        "id": "jXr-vHhyk6rr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the iterative training loop\n",
        "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    w, b = params\n",
        "\n",
        "    t_p = model(t_u, w, b) # forward pass\n",
        "    loss = loss_fn(t_p, t_c)\n",
        "    grad = grad_fn(t_u, t_c, t_p, w, b) # backward pass\n",
        "\n",
        "    params = params - learning_rate * grad\n",
        "    print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "  return params"
      ],
      "metadata": {
        "id": "gw-7yMfZlANX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, learning_rate, params, t_u, t_c,\n",
        "                  print_params=True):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        w, b = params\n",
        "\n",
        "        t_p = model(t_u, w, b)  # forward pass\n",
        "        loss = loss_fn(t_p, t_c)\n",
        "        grad = grad_fn(t_u, t_c, t_p, w, b)  # backward pass\n",
        "\n",
        "        params = params - learning_rate * grad\n",
        "\n",
        "        if epoch in {1, 2, 3, 10, 11, 99, 100, 4000, 5000}:  # <3>\n",
        "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "            if print_params:\n",
        "                print('    Params:', params)\n",
        "                print('    Grad:  ', grad)\n",
        "        if epoch in {4, 12, 101}:\n",
        "            print('...')\n",
        "\n",
        "        if not torch.isfinite(loss).all():\n",
        "            break  # <3>\n",
        "            \n",
        "    return params"
      ],
      "metadata": {
        "id": "-5Mmawz_iV8L"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(\n",
        "  n_epochs = 100,\n",
        "  learning_rate = 1e-2,\n",
        "  params = torch.tensor([1.0, 0.0]),\n",
        "  t_u = t_u,\n",
        "  t_c = t_c)\n",
        "# training blow up due to large learning rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkOZIplHlGkA",
        "outputId": "6e8a7dc1-7df0-4cfa-822b-b192f89333c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss 1763.884766\n",
            "    Params: tensor([-44.1730,  -0.8260])\n",
            "    Grad:   tensor([4517.2964,   82.6000])\n",
            "Epoch 2, Loss 5802484.500000\n",
            "    Params: tensor([2568.4011,   45.1637])\n",
            "    Grad:   tensor([-261257.4062,   -4598.9702])\n",
            "Epoch 3, Loss 19408029696.000000\n",
            "    Params: tensor([-148527.7344,   -2616.3931])\n",
            "    Grad:   tensor([15109614.0000,   266155.6875])\n",
            "...\n",
            "Epoch 10, Loss 90901105189019073810297959556841472.000000\n",
            "    Params: tensor([3.2144e+17, 5.6621e+15])\n",
            "    Grad:   tensor([-3.2700e+19, -5.7600e+17])\n",
            "Epoch 11, Loss inf\n",
            "    Params: tensor([-1.8590e+19, -3.2746e+17])\n",
            "    Grad:   tensor([1.8912e+21, 3.3313e+19])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.8590e+19, -3.2746e+17])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(\n",
        "  n_epochs = 100,\n",
        "  learning_rate = 1e-4,\n",
        "  params = torch.tensor([1.0, 0.0]),\n",
        "  t_u = t_u,\n",
        "  t_c = t_c)\n",
        "# reduce learning rate, behaviour stable\n",
        "# however because update are small, loss decreases very slowly and evantualy stalls\n",
        "# note that the gradient for w is much larger than that for b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zupBBzRllMDb",
        "outputId": "82796857-87d0-45d2-d026-e0b7876d42fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss 1763.884766\n",
            "    Params: tensor([ 0.5483, -0.0083])\n",
            "    Grad:   tensor([4517.2964,   82.6000])\n",
            "Epoch 2, Loss 323.090515\n",
            "    Params: tensor([ 0.3623, -0.0118])\n",
            "    Grad:   tensor([1859.5493,   35.7843])\n",
            "Epoch 3, Loss 78.929634\n",
            "    Params: tensor([ 0.2858, -0.0135])\n",
            "    Grad:   tensor([765.4666,  16.5122])\n",
            "...\n",
            "Epoch 10, Loss 29.105247\n",
            "    Params: tensor([ 0.2324, -0.0166])\n",
            "    Grad:   tensor([1.4803, 3.0544])\n",
            "Epoch 11, Loss 29.104168\n",
            "    Params: tensor([ 0.2323, -0.0169])\n",
            "    Grad:   tensor([0.5781, 3.0384])\n",
            "...\n",
            "Epoch 99, Loss 29.023582\n",
            "    Params: tensor([ 0.2327, -0.0435])\n",
            "    Grad:   tensor([-0.0533,  3.0226])\n",
            "Epoch 100, Loss 29.022667\n",
            "    Params: tensor([ 0.2327, -0.0438])\n",
            "    Grad:   tensor([-0.0532,  3.0226])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2327, -0.0438])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize the gradient, instead of setting up different learning rate for different parameter, we change the inputs so that the gradients aren't quite so different.\n",
        "# why this normalization works? need to keep the range of input within range of -1.0 to 1.0.\n",
        "t_un = 0.1 * t_u\n",
        "training_loop(\n",
        "  n_epochs = 100,\n",
        "  learning_rate = 1e-2,\n",
        "  params = torch.tensor([1.0, 0.0]),\n",
        "  t_u = t_un,\n",
        "  t_c = t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ces889UmlT1s",
        "outputId": "08f78a55-0e32-42fe-acd2-18c06b319c01"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss 80.364342\n",
            "    Params: tensor([1.7761, 0.1064])\n",
            "    Grad:   tensor([-77.6140, -10.6400])\n",
            "Epoch 2, Loss 37.574913\n",
            "    Params: tensor([2.0848, 0.1303])\n",
            "    Grad:   tensor([-30.8623,  -2.3864])\n",
            "Epoch 3, Loss 30.871077\n",
            "    Params: tensor([2.2094, 0.1217])\n",
            "    Grad:   tensor([-12.4631,   0.8587])\n",
            "...\n",
            "Epoch 10, Loss 29.030489\n",
            "    Params: tensor([ 2.3232, -0.0710])\n",
            "    Grad:   tensor([-0.5355,  2.9295])\n",
            "Epoch 11, Loss 28.941877\n",
            "    Params: tensor([ 2.3284, -0.1003])\n",
            "    Grad:   tensor([-0.5240,  2.9264])\n",
            "...\n",
            "Epoch 99, Loss 22.214186\n",
            "    Params: tensor([ 2.7508, -2.4910])\n",
            "    Grad:   tensor([-0.4453,  2.5208])\n",
            "Epoch 100, Loss 22.148710\n",
            "    Params: tensor([ 2.7553, -2.5162])\n",
            "    Grad:   tensor([-0.4446,  2.5165])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2.7553, -2.5162])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# increase the number of epoch\n",
        "params = training_loop(\n",
        "  n_epochs = 5000,\n",
        "  learning_rate = 1e-2,\n",
        "  params = torch.tensor([1.0, 0.0]),\n",
        "  t_u = t_un,\n",
        "  t_c = t_c)\n",
        "\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmdOpWD6lb_4",
        "outputId": "e3a28d12-1e08-4555-8da4-c729f7c02ce8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss 80.364342\n",
            "    Params: tensor([1.7761, 0.1064])\n",
            "    Grad:   tensor([-77.6140, -10.6400])\n",
            "Epoch 2, Loss 37.574913\n",
            "    Params: tensor([2.0848, 0.1303])\n",
            "    Grad:   tensor([-30.8623,  -2.3864])\n",
            "Epoch 3, Loss 30.871077\n",
            "    Params: tensor([2.2094, 0.1217])\n",
            "    Grad:   tensor([-12.4631,   0.8587])\n",
            "...\n",
            "Epoch 10, Loss 29.030489\n",
            "    Params: tensor([ 2.3232, -0.0710])\n",
            "    Grad:   tensor([-0.5355,  2.9295])\n",
            "Epoch 11, Loss 28.941877\n",
            "    Params: tensor([ 2.3284, -0.1003])\n",
            "    Grad:   tensor([-0.5240,  2.9264])\n",
            "...\n",
            "Epoch 99, Loss 22.214186\n",
            "    Params: tensor([ 2.7508, -2.4910])\n",
            "    Grad:   tensor([-0.4453,  2.5208])\n",
            "Epoch 100, Loss 22.148710\n",
            "    Params: tensor([ 2.7553, -2.5162])\n",
            "    Grad:   tensor([-0.4446,  2.5165])\n",
            "...\n",
            "Epoch 4000, Loss 2.927680\n",
            "    Params: tensor([  5.3643, -17.2853])\n",
            "    Grad:   tensor([-0.0006,  0.0033])\n",
            "Epoch 5000, Loss 2.927648\n",
            "    Params: tensor([  5.3671, -17.3012])\n",
            "    Grad:   tensor([-0.0001,  0.0006])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the data\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "t_p = model(t_un, *params) # *params: argument unpacking, will pass the elements of params as individual arguments\n",
        "fig = plt.figure(dpi=100)\n",
        "plt.xlabel(\"Temperature (°Fahrenheit)\")\n",
        "plt.ylabel(\"Temperature (°Celsius)\")\n",
        "plt.plot(t_u.numpy(), t_p.detach().numpy())\n",
        "plt.plot(t_u.numpy(), t_c.numpy(), 'o')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "HMLrSYn7liKx",
        "outputId": "5254c3a1-7232-4474-fcf1-8b963cffbbbc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2a53bf5ca0>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backpropagation"
      ],
      "metadata": {
        "id": "PU4IB3xokcvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "# requires_grad tells pytorch to track the entire family tree of tensors resulting from operations on params."
      ],
      "metadata": {
        "id": "0_9zltC7lyzh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params.grad is None\n",
        "# normally the .gard attribute is None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_La6pC_l1Qw",
        "outputId": "a7b279aa-c79c-41d3-fee5-09bacc2453a5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_fn(model(t_u, *params), t_c)\n",
        "loss.backward() # this will calcualte the derivatives using autograd\n",
        "params.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y7-pIfgl4AC",
        "outputId": "bca5e477-ca05-4a39-9462-fcd20015a33e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4517.2969,   82.6000])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE! every time after we compute the derivative using backward, we need to zero the gradient explicitly at each iteration to avoid the derivatives accumulate at leaf nodes.\n",
        "if params.grad is not None:\n",
        "  params.grad.zero_()"
      ],
      "metadata": {
        "id": "vFI2y6oJl6-p"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combining the autogard into training loop coding\n",
        "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    if params.grad is not None: # this should be done any point in the loop prior to calling loss.backward()\n",
        "      params.grad.zero_()\n",
        "    \n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p, t_c)\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      params -= learning_rate * params.grad\n",
        "    if epoch % 500 == 0:\n",
        "      print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "  return params"
      ],
      "metadata": {
        "id": "cymJJX72l-PE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(\n",
        "  n_epochs = 5000,\n",
        "  learning_rate = 1e-2,\n",
        "  params = torch.tensor([1.0, 0.0], requires_grad=True), # make sure we are calculating the gradient\n",
        "  t_u = t_un,\n",
        "  t_c = t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_NJHWwGmHWQ",
        "outputId": "f90f1917-4c96-45d1-b5c9-b19d3ae5ffd7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 7.860115\n",
            "Epoch 1000, Loss 3.828538\n",
            "Epoch 1500, Loss 3.092191\n",
            "Epoch 2000, Loss 2.957698\n",
            "Epoch 2500, Loss 2.933134\n",
            "Epoch 3000, Loss 2.928648\n",
            "Epoch 3500, Loss 2.927830\n",
            "Epoch 4000, Loss 2.927679\n",
            "Epoch 4500, Loss 2.927652\n",
            "Epoch 5000, Loss 2.927647\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization"
      ],
      "metadata": {
        "id": "xseHEkrwnFtF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every optimizer constructor takes a list of parameters as the first input. All parameters passed to the optimizer are retained inside the optimizer object so the optimizer can update their values and access their grad attribute.\n",
        "\n",
        "Each optimizer exposes two methods: .zero_grad() and .step().\n",
        ".zero_grad() zeroes the grad attribute of all the parameters passed to the optimizer upon construction. .step() updates the value of those parameters according to the optimization strategy implemented by the specific optimizer."
      ],
      "metadata": {
        "id": "Ygp4pKepnxi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# different optimization methods provided by pytorch\n",
        "import torch.optim as optim\n",
        "dir(optim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_TYYHK2mK9c",
        "outputId": "85f6fceb-0add-4175-b216-89ad52ad05f3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ASGD',\n",
              " 'Adadelta',\n",
              " 'Adagrad',\n",
              " 'Adam',\n",
              " 'AdamW',\n",
              " 'Adamax',\n",
              " 'LBFGS',\n",
              " 'NAdam',\n",
              " 'Optimizer',\n",
              " 'RAdam',\n",
              " 'RMSprop',\n",
              " 'Rprop',\n",
              " 'SGD',\n",
              " 'SparseAdam',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_functional',\n",
              " '_multi_tensor',\n",
              " 'lr_scheduler',\n",
              " 'swa_utils']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-5\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "# stochastic gradient descent is the vanilla gradient descent.\n",
        "# the word stochastic comes from the fact that the gtradient is typically obtained by averaging over a random subset of all input samples called minibatch."
      ],
      "metadata": {
        "id": "kfqklFcImNz1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_p = model(t_u, *params)\n",
        "loss = loss_fn(t_p, t_c)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khPZMLbhmQF-",
        "outputId": "e8279cda-e9a2-409b-c38d-19374d21905e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9.5483e-01, -8.2600e-04], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "t_p = model(t_un, *params)\n",
        "loss = loss_fn(t_p, t_c)\n",
        "\n",
        "optimizer.zero_grad() # always need to zeroes out previous gradient anywhere in the loop earlier than the .backward()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvm2wfUpmSah",
        "outputId": "17bc40f0-dd96-4c15-c4f7-1d35b55f3dfa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.7761, 0.1064], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p, t_c)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "  return params"
      ],
      "metadata": {
        "id": "C3o_rMKzmXFo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate) # important that this params\n",
        "\n",
        "training_loop(\n",
        "  n_epochs = 5000,\n",
        "  optimizer = optimizer,\n",
        "  params = params,  # and this params are the same object, otherwise the model don't know what to optimize\n",
        "  t_u = t_un,\n",
        "  t_c = t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc1q6flPmdVc",
        "outputId": "21fab3e2-7e79-4e71-98fb-b2e5a7ccf375"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 7.860120\n",
            "Epoch 1000, Loss 3.828538\n",
            "Epoch 1500, Loss 3.092191\n",
            "Epoch 2000, Loss 2.957698\n",
            "Epoch 2500, Loss 2.933134\n",
            "Epoch 3000, Loss 2.928648\n",
            "Epoch 3500, Loss 2.927830\n",
            "Epoch 4000, Loss 2.927679\n",
            "Epoch 4500, Loss 2.927652\n",
            "Epoch 5000, Loss 2.927647\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trying using different optimization function\n",
        "# Adam is more sophisticated optimizier and the learning rate is set adaptively.\n",
        "# It is less sensitive to the parameter scaling, so that we can use the original t_u rather than t_un\n",
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-1\n",
        "optimizer = optim.Adam([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "  n_epochs = 2000,\n",
        "  optimizer = optimizer,\n",
        "  params = params,\n",
        "  t_u = t_u,\n",
        "  t_c = t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npvGABbNmg5n",
        "outputId": "1f23a0e0-64ee-47d1-ac91-2fad97fb1dcc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 7.612900\n",
            "Epoch 1000, Loss 3.086700\n",
            "Epoch 1500, Loss 2.928579\n",
            "Epoch 2000, Loss 2.927644\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  0.5367, -17.3021], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train, Validation and Overfitting"
      ],
      "metadata": {
        "id": "nBg9Oyy_tOIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "\n",
        "shuffled_indices = torch.randperm(n_samples) # generate a random permutation of the tensor elements\n",
        "\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "\n",
        "train_indices, val_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qtdl6mCUmkhp",
        "outputId": "12629715-a62d-40f3-91ae-76aad2467dc7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5, 1, 7, 2, 8, 6, 9, 0, 3]), tensor([ 4, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building the training and validation set using the random index\n",
        "train_t_u = t_u[train_indices]\n",
        "train_t_c = t_c[train_indices]\n",
        "\n",
        "val_t_u = t_u[val_indices]\n",
        "val_t_c = t_c[val_indices]\n",
        "\n",
        "train_t_un = 0.1 * train_t_u\n",
        "val_t_un = 0.1 * val_t_u"
      ],
      "metadata": {
        "id": "7oxvvHnYmokL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c, val_t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    train_t_p = model(train_t_u, *params)\n",
        "    train_loss = loss_fn(train_t_p, train_t_c)\n",
        "\n",
        "    val_t_p = model(val_t_u, *params) \n",
        "    val_loss = loss_fn(val_t_p, val_t_c) # calculate the loss for validation to monitor the progress\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    # no val_loss.backward() since we don't want to train the model on the validation set\n",
        "\n",
        "    if epoch <= 3 or epoch % 500 == 0:\n",
        "      print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
        "            f\" Validation loss {val_loss.item():.4f}\")\n",
        "  return params"
      ],
      "metadata": {
        "id": "j5LlrgDQmq6s"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "  n_epochs = 3000,\n",
        "  optimizer = optimizer,\n",
        "  params = params,\n",
        "  train_t_u = train_t_un,\n",
        "  val_t_u = val_t_un, \n",
        "  train_t_c = train_t_c,\n",
        "  val_t_c = val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcvLzWJbm1C8",
        "outputId": "784391be-7210-40f2-b923-89dc69e7ee16"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 72.7406, Validation loss 114.6712\n",
            "Epoch 2, Training loss 40.2682, Validation loss 46.4569\n",
            "Epoch 3, Training loss 33.9582, Validation loss 27.9884\n",
            "Epoch 500, Training loss 7.0645, Validation loss 6.8510\n",
            "Epoch 1000, Training loss 3.4611, Validation loss 4.2858\n",
            "Epoch 1500, Training loss 2.9574, Validation loss 3.5832\n",
            "Epoch 2000, Training loss 2.8870, Validation loss 3.3564\n",
            "Epoch 2500, Training loss 2.8772, Validation loss 3.2767\n",
            "Epoch 3000, Training loss 2.8758, Validation loss 3.2475\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.2908, -16.8837], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u,\n",
        "                  train_t_c, val_t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    train_t_p = model(train_t_u, *params)\n",
        "    train_loss = loss_fn(train_t_p, train_t_c)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      val_t_p = model(val_t_u, *params)\n",
        "      val_loss = loss_fn(val_t_p, val_t_c)\n",
        "      assert val_loss.requires_grad == False # manually switch off grad calculation for validation set\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "TKqI7g67m5ki"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_forward(t_u, t_c, is_train): # alternatively, we could also pass in whether to construct the autograd as parameter\n",
        "  with torch.set_grad_enabled(is_train):\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p, t_c)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "sO7BRMIYnATs"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using NN network"
      ],
      "metadata": {
        "id": "S2WWNahbv0uT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch has a whole submodule dedicated to neural networks, called torch.nn. It contains the building blocks needed to create all sorts of neural network architectures. Those building blocks are called modulus (layers in other frameworks)."
      ],
      "metadata": {
        "id": "Wul1nRuug8d_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "t_c = torch.tensor(t_c).unsqueeze(1) # <1>\n",
        "t_u = torch.tensor(t_u).unsqueeze(1) # <1>\n",
        "\n",
        "t_u.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40VROaPrjT8Y",
        "outputId": "6ba37c0d-869f-4766-b74c-ad478047474b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "\n",
        "train_indices, val_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZHvWtfMjXVz",
        "outputId": "07952347-ad25-4365-d707-38095d12b3cd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1,  3,  7,  6,  8,  5, 10,  4,  9]), tensor([2, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_u_train = t_u[train_indices]\n",
        "t_c_train = t_c[train_indices]\n",
        "\n",
        "t_u_val = t_u[val_indices]\n",
        "t_c_val = t_c[val_indices]\n",
        "\n",
        "t_un_train = 0.1 * t_u_train\n",
        "t_un_val = 0.1 * t_u_val"
      ],
      "metadata": {
        "id": "1oCz5UaZjaMr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3sG7_anr04u",
        "outputId": "9ac78e45-5911-48dc-e043-cf6b1ab0bd02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0682],\n",
              "        [-0.2397]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "linear_model = nn.Linear(1, 1) # the number of input features, and number of output features. There's a potential key, whether the linear model includes a bias or not, default is True\n",
        "linear_model(t_un_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling any module (layer) from nn.Module is equal to calling a method named forward in that module. It executes the forward computation."
      ],
      "metadata": {
        "id": "CV8RZ40fmB6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.weight, linear_model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKtX3lKrigDA",
        "outputId": "95df9fe4-207a-4c21-ce87-82a37fcf1f9c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[0.1369]], requires_grad=True), Parameter containing:\n",
              " tensor([-0.7284], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model(torch.ones(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-nT1TxcotYS",
        "outputId": "94cdbd2d-86b2-4cad-bcfa-42b1be5c2cd0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.5915], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model design and optimization"
      ],
      "metadata": {
        "id": "X3zij6002qL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "linear_model = nn.Linear(1,1)\n",
        "optimizer = optim.SGD(\n",
        "  linear_model.parameters(), # replaces [params]\n",
        "  lr=1e-2\n",
        ")"
      ],
      "metadata": {
        "id": "sjAAZi9eo3o6"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(linear_model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_RYcVyJrxeF",
        "outputId": "bc4b9f69-9360-487b-b454-ddf8bd12a2cc"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[0.7073]], requires_grad=True), Parameter containing:\n",
              " tensor([-0.2451], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val,\n",
        "                  t_c_train, t_c_val):\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    t_p_train = model(t_u_train)\n",
        "    loss_train = loss_fn(t_p_train, t_c_train)\n",
        "\n",
        "    t_p_val = model(t_u_val)\n",
        "    loss_val = loss_fn(t_p_val, t_c_val)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch == 1 or epoch%1000 == 0:\n",
        "      print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
        "            f\" Validation loss {loss_val.item():.4f}\")"
      ],
      "metadata": {
        "id": "SlMH2_Aar1bT"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = nn.Linear(1,1)\n",
        "optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 3000,\n",
        "    optimizer = optimizer,\n",
        "    model = linear_model,\n",
        "    loss_fn = nn.MSELoss(),\n",
        "    t_u_train = t_un_train,\n",
        "    t_u_val = t_un_val,\n",
        "    t_c_train = t_c_train,\n",
        "    t_c_val = t_c_val\n",
        ")\n",
        "\n",
        "linear_model.weight, linear_model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW5gd9gstBBP",
        "outputId": "8d804e63-5bb7-4db6-f7ca-40f755711be1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 309.9214, Validation loss 179.2974\n",
            "Epoch 1000, Training loss 3.9721, Validation loss 4.2551\n",
            "Epoch 2000, Training loss 3.2314, Validation loss 2.1787\n",
            "Epoch 3000, Training loss 3.2099, Validation loss 1.9104\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[5.2384]], requires_grad=True), Parameter containing:\n",
              " tensor([-16.5808], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequencing the model"
      ],
      "metadata": {
        "id": "I4GaKVlp4Pum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nn provides a simple way to concatenate models\n",
        "seq_model = nn.Sequential(\n",
        "    nn.Linear(1, 13), # this number is arbitrary\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(13, 1) # as long as this number match the previous one\n",
        ")\n",
        "\n",
        "seq_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIYz4Bo3tzof",
        "outputId": "4b9b3aab-cbfe-40ac-8cba-110c65c4a9c3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1, out_features=13, bias=True)\n",
              "  (1): Tanh()\n",
              "  (2): Linear(in_features=13, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[param.shape for param in seq_model.parameters()]\n",
        "# once model.backward() is called, all the parameter will get their derivatives\n",
        "# optimizers will then updates their values accordingly during optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leZGIpej5D6J",
        "outputId": "7778576e-08ac-4060-d25f-573de98cec05"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([13, 1]), torch.Size([13]), torch.Size([1, 13]), torch.Size([1])]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in seq_model.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9gCSalI5Izm",
        "outputId": "1c6dd742-732f-4eae-c4ac-19d40d864855"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.weight torch.Size([13, 1])\n",
            "0.bias torch.Size([13])\n",
            "2.weight torch.Size([1, 13])\n",
            "2.bias torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# name the submodules to better differentiate them\n",
        "from collections import OrderedDict\n",
        "\n",
        "seq_model = nn.Sequential(OrderedDict([\n",
        "    ('hidden_linear', nn.Linear(1,8)),\n",
        "    ('hidden_activation', nn.Tanh()),\n",
        "    ('output_linear', nn.Linear(8,1))\n",
        "]))\n",
        "\n",
        "seq_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQMqZml454-u",
        "outputId": "f583ad21-bbe8-4b9c-f150-b57600c2d5f8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (hidden_linear): Linear(in_features=1, out_features=8, bias=True)\n",
              "  (hidden_activation): Tanh()\n",
              "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in seq_model.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op1jKgbq6ZC1",
        "outputId": "6f999d4d-c3b3-4e2f-d277-82e1b8f7778b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_linear.weight torch.Size([8, 1])\n",
            "hidden_linear.bias torch.Size([8])\n",
            "output_linear.weight torch.Size([1, 8])\n",
            "output_linear.bias torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(seq_model.parameters(), lr=1e-3)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = optimizer,\n",
        "    model = seq_model,\n",
        "    loss_fn = nn.MSELoss(),\n",
        "    t_u_train = t_un_train,\n",
        "    t_u_val = t_un_val,\n",
        "    t_c_train = t_c_train,\n",
        "    t_c_val = t_c_val\n",
        ")\n",
        "\n",
        "print('output', seq_model(t_un_val))\n",
        "print('answer', t_c_val)\n",
        "print('hidden', seq_model.hidden_linear.weight.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZNy9yb06jzm",
        "outputId": "4c140a14-d91d-4054-d6dd-5a0a8b6d78f0"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 1.5545, Validation loss 4.4465\n",
            "Epoch 1000, Training loss 1.5154, Validation loss 3.7678\n",
            "Epoch 2000, Training loss 1.4892, Validation loss 4.0569\n",
            "Epoch 3000, Training loss 1.4676, Validation loss 4.2991\n",
            "Epoch 4000, Training loss 1.4495, Validation loss 4.5063\n",
            "Epoch 5000, Training loss 1.4342, Validation loss 4.6859\n",
            "output tensor([[12.6090],\n",
            "        [ 2.8929]], grad_fn=<AddmmBackward0>)\n",
            "answer tensor([[15.0000],\n",
            "        [ 0.5000]])\n",
            "hidden tensor([[ 0.1569],\n",
            "        [ 0.1680],\n",
            "        [-0.2100],\n",
            "        [ 7.9316],\n",
            "        [ 0.1618],\n",
            "        [ 8.2613],\n",
            "        [ 7.8252],\n",
            "        [-8.3325]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize and compare with linear model\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "t_range = torch.arange(20., 90.).unsqueeze(1)\n",
        "fig = plt.figure(dpi=100)\n",
        "plt.xlabel(\"Fahrenheit\")\n",
        "plt.ylabel(\"Celsius\")\n",
        "plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n",
        "plt.plot(t_range.numpy(), seq_model(0.1 * t_range).detach().numpy(), 'c-')\n",
        "plt.plot(t_u.numpy(), seq_model(0.1 * t_u).detach().numpy(), 'kx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "RLH7Z6Kd7iYm",
        "outputId": "b15a357a-8f54-46e9-ea39-b2f04206126e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2a4891f280>]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}